{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from csv import reader\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace headers (Data Wrangling with Python pg. 154 – 163)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'], ['0', '-1.3598071336738', '-0.0727811733098497', '2.53634673796914', '1.37815522427443', '-0.338320769942518', '0.462387777762292', '0.239598554061257', '0.0986979012610507', '0.363786969611213', '0.0907941719789316', '-0.551599533260813', '-0.617800855762348', '-0.991389847235408', '-0.311169353699879', '1.46817697209427', '-0.470400525259478', '0.207971241929242', '0.0257905801985591', '0.403992960255733', '0.251412098239705', '-0.018306777944153', '0.277837575558899', '-0.110473910188767', '0.0669280749146731', '0.128539358273528', '-0.189114843888824', '0.133558376740387', '-0.0210530534538215', '149.62', '0'], ['0', '1.19185711131486', '0.26615071205963', '0.16648011335321', '0.448154078460911', '0.0600176492822243', '-0.0823608088155687', '-0.0788029833323113', '0.0851016549148104', '-0.255425128109186', '-0.166974414004614', '1.61272666105479', '1.06523531137287', '0.48909501589608', '-0.143772296441519', '0.635558093258208', '0.463917041022171', '-0.114804663102346', '-0.183361270123994', '-0.145783041325259', '-0.0690831352230203', '-0.225775248033138', '-0.638671952771851', '0.101288021253234', '-0.339846475529127', '0.167170404418143', '0.125894532368176', '-0.00898309914322813', '0.0147241691924927', '2.69', '0'], ['1', '-1.35835406159823', '-1.34016307473609', '1.77320934263119', '0.379779593034328', '-0.503198133318193', '1.80049938079263', '0.791460956450422', '0.247675786588991', '-1.51465432260583', '0.207642865216696', '0.624501459424895', '0.066083685268831', '0.717292731410831', '-0.165945922763554', '2.34586494901581', '-2.89008319444231', '1.10996937869599', '-0.121359313195888', '-2.26185709530414', '0.524979725224404', '0.247998153469754', '0.771679401917229', '0.909412262347719', '-0.689280956490685', '-0.327641833735251', '-0.139096571514147', '-0.0553527940384261', '-0.0597518405929204', '378.66', '0'], ['1', '-0.966271711572087', '-0.185226008082898', '1.79299333957872', '-0.863291275036453', '-0.0103088796030823', '1.24720316752486', '0.23760893977178', '0.377435874652262', '-1.38702406270197', '-0.0549519224713749', '-0.226487263835401', '0.178228225877303', '0.507756869957169', '-0.28792374549456', '-0.631418117709045', '-1.0596472454325', '-0.684092786345479', '1.96577500349538', '-1.2326219700892', '-0.208037781160366', '-0.108300452035545', '0.00527359678253453', '-0.190320518742841', '-1.17557533186321', '0.647376034602038', '-0.221928844458407', '0.0627228487293033', '0.0614576285006353', '123.5', '0']]\n"
     ]
    }
   ],
   "source": [
    "data_rdr = reader(open('C:/Users/Tyler/Desktop/540 Python/Mid-Term/Data/creditcard.csv', 'r', encoding = 'utf8' ))\n",
    "\n",
    "data_rows = [d for d in data_rdr]\n",
    "\n",
    "print(data_rows[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Time', 'Time')]\n"
     ]
    }
   ],
   "source": [
    "all_short_data = [d[0] for d in data_rows]\n",
    "\n",
    "skip_index = []\n",
    "\n",
    "for header in data_rows[0]:\n",
    "    if header not in all_short_data:\n",
    "        index = data_rows[0].index(header)\n",
    "        skip_index.append(index)\n",
    "        \n",
    "new_data = []\n",
    "\n",
    "for row in data_rows[1:]:\n",
    "    new_row = []\n",
    "    for i, d in enumerate(row):\n",
    "        if i not in skip_index:\n",
    "            new_row.append(d)\n",
    "    new_data.append(new_row)\n",
    "    \n",
    "zipped_data = []\n",
    "\n",
    "for drow in new_data:\n",
    "    zipped_data.append(list(zip(data_rows, drow)))\n",
    "    \n",
    "data_headers = []\n",
    "\n",
    "for i, header in enumerate(data_rows[0]):\n",
    "    if i not in skip_index:\n",
    "        data_headers.append(header)\n",
    "        \n",
    "header_match = list(zip(data_headers, all_short_data))\n",
    "\n",
    "print(header_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Data to a Readable Format (Data Wrangling with Python pg. 164 – 168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "Answer: 0\n"
     ]
    }
   ],
   "source": [
    "for x in zipped_data[0]:\n",
    "    print ('Question: {}\\nAnswer: {}'.format(\n",
    "        x[0], x[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float: 1324.3213\n",
      "integer: 43,890,923,148,390,284\n",
      "percentage: 32.40%\n"
     ]
    }
   ],
   "source": [
    "example_dict = {\n",
    "    'float_number': 1324.321325493,\n",
    "    'very_large_integer': 43890923148390284,\n",
    "    'percentage': .324,\n",
    "}\n",
    "\n",
    "string_to_print = \"float: {float_number:.4f}\\n\"\n",
    "string_to_print += \"integer: {very_large_integer:,}\\n\"\n",
    "string_to_print += \"percentage: {percentage:.2%}\"\n",
    "\n",
    "print (string_to_print.format(**example_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, (['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'], '0'))\n"
     ]
    }
   ],
   "source": [
    "for x in enumerate(zipped_data[0][:20]):\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify outliers and bad data (Data Wrangling with Python pg. 169 – 174)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in zipped_data:\n",
    "    for answer in row:\n",
    "        if answer[1] is None:\n",
    "            print (answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "na_count = {}\n",
    "\n",
    "for row in zipped_data:\n",
    "    for resp in row:\n",
    "        question = resp[0][1]\n",
    "        answer = resp[1]\n",
    "        if answer == 'NA':\n",
    "            if question in na_count.keys():\n",
    "                na_count[question] += 1\n",
    "            else:\n",
    "                na_count[question] = 1\n",
    "                \n",
    "print(na_count)\n",
    "                \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'V1': {'digit': 284806, 'boolean': 0, 'empty': 0, 'time_related': 0, 'text': 0, 'unknown': 1}}\n"
     ]
    }
   ],
   "source": [
    "datatypes = {}\n",
    "\n",
    "start_dict = {'digit': 0, 'boolean': 0,\n",
    "              'empty': 0, 'time_related': 0,\n",
    "              'text': 0, 'unknown': 0\n",
    "             }\n",
    "\n",
    "for row in zipped_data:\n",
    "    for resp in row:\n",
    "        question = resp[0][1]\n",
    "        answer = resp[1]\n",
    "        key = 'unknown'\n",
    "        if answer.isdigit():\n",
    "            key = 'digit'\n",
    "        elif answer in ['Yes', 'No', 'True', 'False']:\n",
    "            key = 'boolean'\n",
    "        elif answer.isspace():\n",
    "            key = 'empty'\n",
    "        elif answer.find('/') > 0 or answer.find(':') > 0:\n",
    "            key = 'time_related'\n",
    "        elif answer.isalpha():\n",
    "            key = 'text'\n",
    "        if question not in datatypes.keys():\n",
    "            datatypes[question] = start_dict.copy()\n",
    "            \n",
    "        datatypes[question][key] += 1\n",
    "        \n",
    "print (datatypes)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Duplicates (Data Wrangling with Python pg. 175 – 178)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, (['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'], '0'))\n"
     ]
    }
   ],
   "source": [
    "for x in enumerate(zipped_data[0]):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "set_of_lines = set([x[0][1] for x in zipped_data])\n",
    "\n",
    "uniques = [x for x in zipped_data if not set_of_lines.remove(x[0][1])]\n",
    "\n",
    "print (set_of_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct Fuzzy Matching (if you don’t have an obvious example to do this with in your data, create categories and use Fuzzy Matching to lump data together) (Data Wrangling with Python pg. 179 – 188)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    " #I dont have an example using my data so ill be using an example\n",
    "    \n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "Str1 = \"Taco Pizza.\"\n",
    "Str2 = \"taco Pizza\"\n",
    "\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "\n",
    "print(Ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"Colorado Buffaloes\"\n",
    "Str2 = \"Colorado\"\n",
    "\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "57\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"roe v. wade\"\n",
    "Str2 = \"Wade v. Roe\"\n",
    "\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "\n",
    "Partial_Ratio = fuzz.partial_ratio(Str1.lower(),Str2.lower())\n",
    "\n",
    "Token_Sort_Ratio = fuzz.token_sort_ratio(Str1,Str2)\n",
    "\n",
    "print(Ratio)\n",
    "print(Partial_Ratio)\n",
    "print(Token_Sort_Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('E Corp.', 100), ('e corp park', 90), ('Evil Corporation', 75), ('ephone', 33)]\n",
      "('E Corp.', 100)\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "str2Match = \"e corp.\"\n",
    "strOptions = [\"E Corp.\",\"e corp park\",\"Evil Corporation\",\"ephone\"]\n",
    "\n",
    "Ratios = process.extract(str2Match,strOptions)\n",
    "\n",
    "print(Ratios)\n",
    "\n",
    "# You can also select the string with the highest matching percentage\n",
    "highest = process.extractOne(str2Match,strOptions)\n",
    "\n",
    "print(highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
